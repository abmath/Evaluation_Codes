{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Dependencies\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import keras\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/abhinavmathur/ML Repository/Sample-Codes/Computer Vision/skin-cancer-malignant-vs-benign/train\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#path = os.getcwd()\n",
    "path = os.path.join(os.getcwd(),'skin-cancer-malignant-vs-benign','train')\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['malignant', 'benign']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "types = os.listdir(path)\n",
    "types.pop(0)\n",
    "types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['benign', 'malignant']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Reverse(lst): \n",
    "    return [ele for ele in reversed(lst)] \n",
    "\n",
    "read = Reverse(types)\n",
    "read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.408655881881714  seconds\n"
     ]
    }
   ],
   "source": [
    "# Define label and data lists\n",
    "\n",
    "start = time.time()\n",
    "Data = []\n",
    "res = []\n",
    "\n",
    "for typ in read:\n",
    "    outcome = read.index(typ)\n",
    "    #print(outcome)\n",
    "    file_dir = os.path.join(path,typ)\n",
    "    files = os.listdir(file_dir)\n",
    "    for file in files:\n",
    "        img = cv2.imread(os.path.join(path,typ,file))\n",
    "        Img = Image.fromarray(img, 'RGB')\n",
    "        Img2 = Img.resize((150,150))\n",
    "        Data.append(np.array(Img2))\n",
    "        res.append(outcome)\n",
    "        \n",
    "end = time.time()\n",
    "print(end-start,\" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2637, 150, 150, 3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Images = np.array(Data)\n",
    "res2 = np.array(res)\n",
    "Images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2637 Images of resolution 150 X 150 for RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshufle Images and \n",
    "\n",
    "indexes=np.arange(Images.shape[0]) #Get the total count of rows in an array\n",
    "np.random.shuffle(indexes) # Randomly shuffle row numbers\n",
    "images=Images[indexes] # Rearrange rows in the images data\n",
    "infections=res2[indexes] # Rearrange outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1846 791 2637\n"
     ]
    }
   ],
   "source": [
    "# Split the data into train and test datasets by taking a 80:20 split\n",
    "\n",
    "(X_train, X_test) = images[(int)(0.3*len(images)):],images[:(int)(0.3*len(images))]\n",
    "(Y_train, Y_test) = infections[(int)(0.3*len(infections)):],infections[:(int)(0.3*len(infections))]\n",
    "print(len(X_train),len(X_test),len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1846 791\n"
     ]
    }
   ],
   "source": [
    "print(len(Y_train),len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data by dividing with 255 pixels\n",
    "X_train = X_train.astype('float32')/255 # As we are working on image data we are normalizing data by divinding 255.\n",
    "X_test = X_test.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As this is a classification problem we will need to complete a one hot encoding for all categorical variables\n",
    "\n",
    "Y_train = keras.utils.to_categorical(Y_train,len(np.unique(infections)))\n",
    "Y_test = keras.utils.to_categorical(Y_test,len(np.unique(infections)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 150, 150, 32)      416       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 75, 75, 64)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 37, 37, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 37, 37, 128)       32896     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 41472)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 500)               20736500  \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 1002      \n",
      "=================================================================\n",
      "Total params: 20,779,070\n",
      "Trainable params: 20,779,070\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Defining and training a CNN\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Conv2D(filters=32,kernel_size=2,padding=\"same\",activation=\"relu\",input_shape=(150,150,3)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=64,kernel_size=2,padding=\"same\",activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=128,kernel_size=2,padding=\"same\",activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500,activation=\"sigmoid\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2,activation=\"sigmoid\"))#2 represent output layer neurons \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1846/1846 [==============================] - 73s 39ms/step - loss: 0.8481 - acc: 0.5699\n",
      "Epoch 2/50\n",
      "1846/1846 [==============================] - 70s 38ms/step - loss: 0.5168 - acc: 0.7356\n",
      "Epoch 3/50\n",
      "1846/1846 [==============================] - 83s 45ms/step - loss: 0.4610 - acc: 0.7649\n",
      "Epoch 4/50\n",
      "1846/1846 [==============================] - 75s 41ms/step - loss: 0.4897 - acc: 0.7516\n",
      "Epoch 5/50\n",
      "1846/1846 [==============================] - 82s 44ms/step - loss: 0.4173 - acc: 0.7925\n",
      "Epoch 6/50\n",
      "1846/1846 [==============================] - 86s 47ms/step - loss: 0.4337 - acc: 0.7849\n",
      "Epoch 7/50\n",
      "1846/1846 [==============================] - 81s 44ms/step - loss: 0.3919 - acc: 0.8047\n",
      "Epoch 8/50\n",
      "1846/1846 [==============================] - 101s 55ms/step - loss: 0.3750 - acc: 0.8164\n",
      "Epoch 9/50\n",
      "1846/1846 [==============================] - 74s 40ms/step - loss: 0.3813 - acc: 0.8093\n",
      "Epoch 10/50\n",
      "1846/1846 [==============================] - 74s 40ms/step - loss: 0.3361 - acc: 0.8334\n",
      "Epoch 11/50\n",
      "1846/1846 [==============================] - 84s 45ms/step - loss: 0.3183 - acc: 0.8505\n",
      "Epoch 12/50\n",
      "1846/1846 [==============================] - 79s 43ms/step - loss: 0.3097 - acc: 0.8583\n",
      "Epoch 13/50\n",
      "1846/1846 [==============================] - 76s 41ms/step - loss: 0.2898 - acc: 0.8684\n",
      "Epoch 14/50\n",
      "1846/1846 [==============================] - 93s 50ms/step - loss: 0.3051 - acc: 0.8592\n",
      "Epoch 15/50\n",
      "1846/1846 [==============================] - 92s 50ms/step - loss: 0.2639 - acc: 0.8808\n",
      "Epoch 16/50\n",
      "1846/1846 [==============================] - 81s 44ms/step - loss: 0.2448 - acc: 0.8873\n",
      "Epoch 17/50\n",
      "1846/1846 [==============================] - 77s 42ms/step - loss: 0.2294 - acc: 0.9006\n",
      "Epoch 18/50\n",
      "1846/1846 [==============================] - 79s 43ms/step - loss: 0.2208 - acc: 0.9098\n",
      "Epoch 19/50\n",
      "1846/1846 [==============================] - 76s 41ms/step - loss: 0.2028 - acc: 0.9125\n",
      "Epoch 20/50\n",
      "1846/1846 [==============================] - 77s 42ms/step - loss: 0.1726 - acc: 0.9307\n",
      "Epoch 21/50\n",
      "1846/1846 [==============================] - 73s 39ms/step - loss: 0.1731 - acc: 0.9244\n",
      "Epoch 22/50\n",
      "1846/1846 [==============================] - 71s 38ms/step - loss: 0.1705 - acc: 0.9353\n",
      "Epoch 23/50\n",
      "1846/1846 [==============================] - 71s 38ms/step - loss: 0.1608 - acc: 0.9363\n",
      "Epoch 24/50\n",
      "1846/1846 [==============================] - 71s 38ms/step - loss: 0.1376 - acc: 0.9461\n",
      "Epoch 25/50\n",
      "1846/1846 [==============================] - 70s 38ms/step - loss: 0.1410 - acc: 0.9423\n",
      "Epoch 26/50\n",
      "1846/1846 [==============================] - 70s 38ms/step - loss: 0.1363 - acc: 0.9480\n",
      "Epoch 27/50\n",
      "1846/1846 [==============================] - 71s 38ms/step - loss: 0.1149 - acc: 0.9556\n",
      "Epoch 28/50\n",
      "1846/1846 [==============================] - 71s 38ms/step - loss: 0.1071 - acc: 0.9559\n",
      "Epoch 29/50\n",
      "1846/1846 [==============================] - 70s 38ms/step - loss: 0.1002 - acc: 0.9637\n",
      "Epoch 30/50\n",
      "1846/1846 [==============================] - 71s 38ms/step - loss: 0.0803 - acc: 0.9729\n",
      "Epoch 31/50\n",
      "1846/1846 [==============================] - 71s 38ms/step - loss: 0.0776 - acc: 0.9718\n",
      "Epoch 32/50\n",
      "1846/1846 [==============================] - 71s 38ms/step - loss: 0.0790 - acc: 0.9751\n",
      "Epoch 33/50\n",
      "1846/1846 [==============================] - 74s 40ms/step - loss: 0.0581 - acc: 0.9837\n",
      "Epoch 34/50\n",
      "1846/1846 [==============================] - 83s 45ms/step - loss: 0.0562 - acc: 0.9816\n",
      "Epoch 35/50\n",
      "1846/1846 [==============================] - 82s 44ms/step - loss: 0.0584 - acc: 0.9781\n",
      "Epoch 36/50\n",
      "1846/1846 [==============================] - 81s 44ms/step - loss: 0.0521 - acc: 0.9843\n",
      "Epoch 37/50\n",
      "1846/1846 [==============================] - 73s 39ms/step - loss: 0.0459 - acc: 0.9865\n",
      "Epoch 38/50\n",
      "1846/1846 [==============================] - 72s 39ms/step - loss: 0.0305 - acc: 0.9940\n",
      "Epoch 39/50\n",
      "1846/1846 [==============================] - 73s 40ms/step - loss: 0.0335 - acc: 0.9919\n",
      "Epoch 40/50\n",
      "1846/1846 [==============================] - 75s 41ms/step - loss: 0.0311 - acc: 0.9921\n",
      "Epoch 41/50\n",
      "1846/1846 [==============================] - 74s 40ms/step - loss: 0.0443 - acc: 0.9873\n",
      "Epoch 42/50\n",
      "1846/1846 [==============================] - 73s 40ms/step - loss: 0.0232 - acc: 0.9951\n",
      "Epoch 43/50\n",
      "1846/1846 [==============================] - 74s 40ms/step - loss: 0.0170 - acc: 0.9973\n",
      "Epoch 44/50\n",
      "1846/1846 [==============================] - 71s 39ms/step - loss: 0.0280 - acc: 0.9932\n",
      "Epoch 45/50\n",
      "1846/1846 [==============================] - 71s 38ms/step - loss: 0.0166 - acc: 0.9967\n",
      "Epoch 46/50\n",
      "1846/1846 [==============================] - 74s 40ms/step - loss: 0.0169 - acc: 0.9970\n",
      "Epoch 47/50\n",
      "1846/1846 [==============================] - 74s 40ms/step - loss: 0.0090 - acc: 0.9995\n",
      "Epoch 48/50\n",
      "1846/1846 [==============================] - 73s 40ms/step - loss: 0.0076 - acc: 0.9997\n",
      "Epoch 49/50\n",
      "1846/1846 [==============================] - 74s 40ms/step - loss: 0.0089 - acc: 0.9989\n",
      "Epoch 50/50\n",
      "1846/1846 [==============================] - 89s 48ms/step - loss: 0.0079 - acc: 0.9986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb2f34b668>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile the model with loss as categorical_crossentropy and using adam optimizer you can test result by trying RMSProp as well as Momentum\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#Fit the model with min batch size as 50[can tune batch size to some factor of 2^power ] \n",
    "model.fit(X_train,Y_train,batch_size=70,epochs=50,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "791/791 [==============================] - 9s 11ms/step\n",
      "\n",
      " Test_Accuracy:- 0.8565107453638021\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(X_test, Y_test, verbose=1)\n",
    "\n",
    "print('\\n', 'Test_Accuracy:-', accuracy[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['malignant', 'benign']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read test data as done with training data\n",
    "\n",
    "test_path = os.path.join(os.getcwd(),'skin-cancer-malignant-vs-benign','test')\n",
    "types = os.listdir(test_path)\n",
    "types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['benign', 'malignant']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_test = Reverse(types)\n",
    "read_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.796050786972046  seconds\n"
     ]
    }
   ],
   "source": [
    "# Define label and data lists\n",
    "\n",
    "start = time.time()\n",
    "Data_test = []\n",
    "res_test = []\n",
    "\n",
    "for typ in read_test:\n",
    "    outcome = read_test.index(typ)\n",
    "    #print(outcome)\n",
    "    file_dir = os.path.join(test_path,typ)\n",
    "    files = os.listdir(file_dir)\n",
    "    for file in files:\n",
    "        img = cv2.imread(os.path.join(test_path,typ,file))\n",
    "        Img = Image.fromarray(img, 'RGB')\n",
    "        Img2 = Img.resize((150,150))\n",
    "        Data_test.append(np.array(Img2))\n",
    "        res_test.append(outcome)\n",
    "        \n",
    "end = time.time()\n",
    "print(end-start,\" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(660, 150, 150, 3)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Images = np.array(Data_test)\n",
    "res2 = np.array(res_test)\n",
    "Images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "660"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "Images2 = Images.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = keras.utils.to_categorical(res2,len(np.unique(res2)))\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['benign', 'malignant']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "660/660 [==============================] - 7s 11ms/step\n",
      "\n",
      " Test_Accuracy:- 0.8378787886012684\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(Images2, Y, verbose=1)\n",
    "\n",
    "print('\\n', 'Test_Accuracy:-', accuracy[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the keras model\n",
    "\n",
    "model.save('Malignant Skin Tumour Detection CNN Keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
